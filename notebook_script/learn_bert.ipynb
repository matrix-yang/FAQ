{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "BERT_MODEL_PATH = r\"F:/workcode/FAQ/BERT_model\"\n",
    "# a.通过词典导入分词器\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL_PATH+'/bert-base-uncased-vocab.txt') \n",
    "# b. 导入配置文件\n",
    "model_config = transformers.BertConfig.from_pretrained(BERT_MODEL_PATH+'/bert-base-uncased-config.json')\n",
    "# 修改配置\n",
    "#model_config.output_hidden_states = True\n",
    "#model_config.output_attentions = True\n",
    "# 通过配置和路径导入模型\n",
    "model = transformers.BertModel.from_pretrained(BERT_MODEL_PATH+'/bert-base-uncased-pytorch_model.bin',config = model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_plus返回所有编码信息\n",
    "sen_code = tokenizer.encode_plus(\"i like you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'i', 'like', 'you', '[SEP]']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(sen_code['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.eval() # 将模型设为验证模式\n",
    "input_ids = torch.tensor([sen_code['input_ids']]) # 添加batch维度并转化为tensor\n",
    "token_type_ids = torch.tensor([sen_code['token_type_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型转化为eval模式\n",
    "model.eval()\n",
    "# 将模型和数据转移到cuda, 若无cuda,可更换为cpu\n",
    "device = 'cuda'\n",
    "tokens_tensor = input_ids.to(device)\n",
    "segments_tensors = token_type_ids.to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 进行编码\n",
    "with torch.no_grad():\n",
    "    # See the models docstrings for the detail of the inputs\n",
    "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    # Transformers models always output tuples.\n",
    "    # See the models docstrings for the detail of all the outputs\n",
    "    # In our case, the first element is the hidden state of the last layer of the Bert model\n",
    "    encoded_layers = outputs\n",
    "# 得到最终的编码结果encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a,b=encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01590374,  0.06605431, -0.09751298, ..., -0.2026468 ,\n",
       "          0.07909803,  0.15123391],\n",
       "        [ 0.0762463 , -0.26786408, -0.69057244, ...,  0.14479323,\n",
       "          0.754324  ,  0.2614672 ],\n",
       "        [ 0.2831399 , -0.13686614,  0.7657905 , ..., -0.24902762,\n",
       "          0.39826664,  0.09002201],\n",
       "        [-0.32801044, -1.0406164 , -0.04919878, ...,  0.2702459 ,\n",
       "          0.46201882, -0.56252015],\n",
       "        [ 0.7270662 , -0.00392812, -0.16390216, ...,  0.11239298,\n",
       "         -0.5019356 , -0.4152661 ]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTask(torch.nn.Module):\n",
    "    def __init__(self,feature_model_path=BERT_MODEL_PATH+'/bert-base-uncased-pytorch_model.bin'):\n",
    "        super(MyTask,self).__init__()\n",
    "        self.feature_ext=transformers.BertModel.from_pretrained(feature_model_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA任务下的 BEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "import torch\n",
    "import transformers\n",
    "MODEL_PATH = r\"F:/workcode/FAQ/BERT_model\"\n",
    "# 实例化tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH+'/bert-base-uncased-vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入bert的model_config\n",
    "model_config = transformers.BertConfig.from_pretrained(MODEL_PATH+'/bert-base-uncased-config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先新建bert_model\n",
    "bert_model = transformers.BertModel.from_pretrained(MODEL_PATH+'/bert-base-uncased-pytorch_model.bin',config = model_config)\n",
    "# 最终有两个输出，初始位置和结束位置（下面有解释）\n",
    "model_config.num_labels = 2\n",
    "# 同样根据bert的model_config新建BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering(model_config)\n",
    "model.bert = bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定模式\n",
    "model.eval()\n",
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "# 获取input_ids编码\n",
    "input_ids = tokenizer.encode(question, text)\n",
    "# 手动进行token_type_ids编码，可用encode_plus代替\n",
    "token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n",
    "# 得到评分, \n",
    "start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "# 进行逆编码，得到原始的token \n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "#['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'nice', 'puppet', '[SEP]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jim henson ? [SEP] jim henson was a\n"
     ]
    }
   ],
   "source": [
    "# 对输出的答案进行解码的过程\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "# assert answer == \"a nice puppet\" \n",
    "# 这里因为没有经过微调，所以效果不是很好，输出结果不佳。\n",
    "print(answer)\n",
    "# 'was jim henson ? [SEP] jim henson was a nice puppet [SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
