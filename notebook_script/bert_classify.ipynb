{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from utils.process_data import get_dataloader\n",
    "import torch.optim as optim\n",
    "from utils import config\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BertCls(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertCls, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_model_path)\n",
    "        self.liner = torch.nn.Sequential(\n",
    "            torch.nn.Linear(768 * 2, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, ste1, ste2):\n",
    "        ebd1, cls1 = self.bert(ste1)\n",
    "        ebd2, cls2 = self.bert(ste2)\n",
    "        conact = torch.cat((ebd1[:, 0, :], ebd2[:, 0, :]), dim=1)\n",
    "        out = self.liner(conact)\n",
    "        return out\n",
    "\n",
    "\n",
    "def freeze_parameter(cls_model):\n",
    "    for n,p in cls_model.named_parameters():\n",
    "        if 'bert' in n:\n",
    "            p.requires_grad = False\n",
    "    for n,p in cls_model.named_parameters():\n",
    "        if 'bert.encoder.layer.11' in n:\n",
    "            p.requires_grad = True\n",
    "    \n",
    "def train(model, train_data, epco=10):\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    for e in range(epco):\n",
    "        idx = 0\n",
    "        for s1, s2, l in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            y = model(s1, s2)\n",
    "            loss = loss_fn(y, l)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 9:\n",
    "                print('epco:{} iter:{} loss:{}'.format(e, idx, loss))\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "def evaluate(model, test_data):\n",
    "    model.eval()\n",
    "    right = 0.1\n",
    "    preidt_p = 0.1\n",
    "    positive = 0.1\n",
    "    with torch.no_grad():\n",
    "        for s1, s2, l in test_data:\n",
    "            y = model(s1, s2)\n",
    "            y = y.cpu().view(-1).numpy()\n",
    "            y[y > 0.5] = 1\n",
    "            y[y <= 0.5] = 0\n",
    "            preidt_p += y.sum()\n",
    "            \n",
    "            l = l.cpu().view(-1).numpy()\n",
    "            positive += l.sum()\n",
    "            l[l==0]=-1\n",
    "            right += (y == l).sum()\n",
    "    P = right / preidt_p\n",
    "    R = right / positive\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    print('P:{} R:{} F1:{}'.format(P, R, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epco:0 iter:9 loss:0.7578407526016235\n",
      "epco:0 iter:19 loss:0.6944000720977783\n",
      "epco:0 iter:29 loss:0.6681841611862183\n",
      "epco:0 iter:39 loss:0.6725636720657349\n",
      "epco:0 iter:49 loss:0.6306008696556091\n",
      "epco:0 iter:59 loss:0.6407224535942078\n",
      "epco:1 iter:9 loss:0.5894600749015808\n",
      "epco:1 iter:19 loss:0.6995288729667664\n",
      "epco:1 iter:29 loss:0.607067346572876\n",
      "epco:1 iter:39 loss:0.5976476669311523\n",
      "epco:1 iter:49 loss:0.6352135539054871\n",
      "epco:1 iter:59 loss:0.5339100956916809\n",
      "epco:2 iter:9 loss:0.577693521976471\n",
      "epco:2 iter:19 loss:0.42934751510620117\n",
      "epco:2 iter:29 loss:0.43866056203842163\n",
      "epco:2 iter:39 loss:0.5503401756286621\n",
      "epco:2 iter:49 loss:0.6623993515968323\n",
      "epco:2 iter:59 loss:0.5927455425262451\n",
      "epco:3 iter:9 loss:0.6484025716781616\n",
      "epco:3 iter:19 loss:0.4324478507041931\n",
      "epco:3 iter:29 loss:0.6393012404441833\n",
      "epco:3 iter:39 loss:0.5291118025779724\n",
      "epco:3 iter:49 loss:0.5391762256622314\n",
      "epco:3 iter:59 loss:0.5937991738319397\n",
      "epco:4 iter:9 loss:0.6072697043418884\n",
      "epco:4 iter:19 loss:0.48190221190452576\n",
      "epco:4 iter:29 loss:0.5354458093643188\n",
      "epco:4 iter:39 loss:0.4710100293159485\n",
      "epco:4 iter:49 loss:0.49968641996383667\n",
      "epco:4 iter:59 loss:0.47231635451316833\n",
      "epco:5 iter:9 loss:0.4767780601978302\n",
      "epco:5 iter:19 loss:0.6085220575332642\n",
      "epco:5 iter:29 loss:0.3904356062412262\n",
      "epco:5 iter:39 loss:0.5334702134132385\n",
      "epco:5 iter:49 loss:0.3967650532722473\n",
      "epco:5 iter:59 loss:0.5369422435760498\n",
      "epco:6 iter:9 loss:0.661552906036377\n",
      "epco:6 iter:19 loss:0.49204903841018677\n",
      "epco:6 iter:29 loss:0.44881772994995117\n",
      "epco:6 iter:39 loss:0.49974876642227173\n",
      "epco:6 iter:49 loss:0.6023669838905334\n",
      "epco:6 iter:59 loss:0.5255155563354492\n",
      "epco:7 iter:9 loss:0.32416701316833496\n",
      "epco:7 iter:19 loss:0.5307276844978333\n",
      "epco:7 iter:29 loss:0.43604713678359985\n",
      "epco:7 iter:39 loss:0.41054633259773254\n",
      "epco:7 iter:49 loss:0.462476521730423\n",
      "epco:7 iter:59 loss:0.6357935667037964\n",
      "epco:8 iter:9 loss:0.32822999358177185\n",
      "epco:8 iter:19 loss:0.6091296076774597\n",
      "epco:8 iter:29 loss:0.49657002091407776\n",
      "epco:8 iter:39 loss:0.6064577102661133\n",
      "epco:8 iter:49 loss:0.587099552154541\n",
      "epco:8 iter:59 loss:0.36527982354164124\n",
      "epco:9 iter:9 loss:0.3471905589103699\n",
      "epco:9 iter:19 loss:0.43156030774116516\n",
      "epco:9 iter:29 loss:0.46943482756614685\n",
      "epco:9 iter:39 loss:0.21632088720798492\n",
      "epco:9 iter:49 loss:0.3844545781612396\n",
      "epco:9 iter:59 loss:0.2332351952791214\n",
      "P:1.0514304082288652 R:1.3854299025836512 F1:1.1955409356725146\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = get_dataloader()\n",
    "cls_model = BertCls()\n",
    "cls_model.cuda()\n",
    "freeze_parameter(cls_model)\n",
    "train(cls_model, train_data)\n",
    "evaluate(cls_model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:0.6399871423979427 R:0.8432867429055485 F1:0.7277046783625731\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.random.rand(32)\n",
    "a[a>0.5]=1\n",
    "a[a<=0.5]=0\n",
    "b=np.random.rand(32)\n",
    "b[b>0.5]=1\n",
    "b[b<=0.5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True, False, False,  True,  True,\n",
       "        True, False,  True, False,  True, False, False,  True, False,\n",
       "        True, False,  True, False, False,  True, False,  True,  True,\n",
       "        True,  True, False, False,  True])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a==1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
